{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pm4py"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing the log"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.conversion.log import converter\n",
    "file_path = \"./Road_Traffic_Fine_Management_Process.xes\"\n",
    "xes_event_log = xes_importer.apply(file_path)\n",
    "\n",
    "event_log = converter.apply(xes_event_log, variant=converter.Variants.TO_DATA_FRAME)\n",
    "\n",
    "event_log"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_activities = pm4py.get_start_activities(event_log)\n",
    "end_activities = pm4py.get_end_activities(event_log)\n",
    "print(\"Start activities: {}\\nEnd activities: {}\".format(start_activities, end_activities))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Process Discovery\n",
    "Petri Net (using two different algorithms)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pm4py.visualization.petri_net import visualizer as pn_visualizer\n",
    "\n",
    "# Alpha Miner\n",
    "from pm4py.algo.discovery.alpha import algorithm as alpha_miner\n",
    "alpha_net, alpha_initial_marking, alpha_final_marking = alpha_miner.apply(event_log)\n",
    "alpha_graphviz = pn_visualizer.apply(alpha_net, alpha_initial_marking, alpha_final_marking)\n",
    "alpha_graphviz.graph_attr['bgcolor'] = 'white'\n",
    "pn_visualizer.view(alpha_graphviz)\n",
    "# pn_visualizer.save(alpha_graphviz, \"pn_alpha_miner.png\")\n",
    "\n",
    "# Inductive Miner\n",
    "from pm4py.algo.discovery.inductive import algorithm as inductive_miner\n",
    "ind_net, ind_initial_marking, ind_final_marking = inductive_miner.apply(event_log)\n",
    "ind_graphviz = pn_visualizer.apply(ind_net, ind_initial_marking, ind_final_marking)\n",
    "ind_graphviz.graph_attr['bgcolor'] = 'white'\n",
    "pn_visualizer.view(ind_graphviz)\n",
    "# pn_visualizer.save(ind_graphviz, \"pn_inductive_miner.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Other possible process models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Process Tree\n",
    "process_tree = pm4py.discover_process_tree_inductive(event_log)\n",
    "pm4py.view_process_tree(process_tree)\n",
    "\n",
    "# BPMN Model\n",
    "bpmn_model = pm4py.convert_to_bpmn(process_tree)\n",
    "pm4py.view_bpmn(bpmn_model)\n",
    "\n",
    "# Process Map (Directly Follows Graph)\n",
    "dfg, start_activities, end_activities = pm4py.discover_dfg(event_log)\n",
    "pm4py.view_dfg(dfg, start_activities, end_activities)\n",
    "\n",
    "# Heuristic Miner\n",
    "heu = pm4py.discover_heuristics_net(event_log)\n",
    "pm4py.view_heuristics_net(heu)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision points"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{p_7: ['Appeal to Judge',\n  'Send Fine',\n  'Insert Date Appeal to Prefecture',\n  'Payment']}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each decision point (place with at least 2 outgoing arcs), gets the labels of the target transitions\n",
    "# Invisible transitions (in case of the inductive miner) are not taken into account for now: decision nodes with invisible transitions are simply not considered in the analysis\n",
    "\n",
    "decision_points_and_trans = dict()\n",
    "\n",
    "def find_decision_point_transitions(dec_point):\n",
    "    for arc in dec_point.out_arcs:\n",
    "        if arc.target.label is not None:\n",
    "            decision_points_and_trans[dec_point].append(arc.target.label)\n",
    "        #else:\n",
    "            #trans_out = arc.target\n",
    "            #trans_out_arcs = trans_out.out_arcs\n",
    "            #for arc2 in trans_out_arcs:\n",
    "                #find_decision_point_transitions(arc2.target)\n",
    "\n",
    "    # Removing nodes with following invisible transitions (= only one transition in the dictionary)\n",
    "    if len(decision_points_and_trans[dec_point]) < 2:\n",
    "        del decision_points_and_trans[dec_point]\n",
    "\n",
    "for place in ind_net.places:\n",
    "    if len(place.out_arcs) >= 2:\n",
    "        decision_points_and_trans[place] = list()\n",
    "        find_decision_point_transitions(place)\n",
    "\n",
    "decision_points_and_trans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Observation instances\n",
    "Now that for every decision point we have the list of observed transitions, we need to build the observation instances.\n",
    "The observation instances of a decision point are the instances (x, t) where x are the observed values of the attributes, while t is the observed transition.\n",
    "So, every time we see a transition t in the event log, we retrieve the values x of the attributes before the transition happens, and we add the instance to the observation instances for that decision point."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "amount = dict()\n",
    "gb = event_log.groupby(['case:concept:name'])\n",
    "\n",
    "# ONLY 1 DECISION POINT FOR NOW, NEEDS TO BE GENERALIZED (MULTI-DIMENSIONAL MATRIX?)\n",
    "def create_dataframe_for_dp(dp):\n",
    "    trans_dataframes = list()\n",
    "    for trans in decision_points_and_trans[dp]:\n",
    "        amount[trans] = list()\n",
    "        # For each transition, I put in this list the values of the attributes observed before that transition happened (TESTING ONLY WITH ATTRIBUTE \"AMOUNT\" FOR NOW)\n",
    "        # Need to look in the event_log dataframe and handle NaN/NIL values, going back within the same case\n",
    "        for case in gb.groups:\n",
    "            for row in gb.groups[case]:\n",
    "                if event_log.iloc[row]['concept:name'] == trans:\n",
    "                    row_iter = row\n",
    "                    # If nan, go back within the same case to find the value (if any) until going back would be too much (beginning of that case)\n",
    "                    while row_iter >= gb.groups[case][0]:\n",
    "                        if not math.isnan(event_log.iloc[row_iter]['amount']):\n",
    "                            amount[trans].append(event_log.iloc[row_iter]['amount'])\n",
    "                            break\n",
    "                        row_iter = row_iter - 1\n",
    "        # Creating the dataframe\n",
    "        df_trans = pd.DataFrame(amount[trans], columns=['amount'])\n",
    "        df_trans['decision point'] = dp\n",
    "        df_trans['transition'] = trans\n",
    "        trans_dataframes.append(df_trans)\n",
    "\n",
    "    res_df = pd.concat(trans_dataframes)\n",
    "    return res_df\n",
    "\n",
    "# For each decision point found, it creates a dataframe containing the attribute values for each event of interest, according to the observed transitions\n",
    "dp_dataframes = list()\n",
    "for decision_point in decision_points_and_trans.keys():\n",
    "    df_dp = create_dataframe_for_dp(decision_point)\n",
    "    dp_dataframes.append(df_dp)\n",
    "\n",
    "# In the end, we have a single dataframe for all the decision points, containing [attribute values, decision point, observed transition] for every event of interest\n",
    "final_df = pd.concat(dp_dataframes)\n",
    "\n",
    "final_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = ['amount']\n",
    "classes = final_df['transition'].unique()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(final_df['amount'], final_df['transition'], random_state=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(max_depth = 2, random_state = 0)\n",
    "\n",
    "# Reshape since we are using only 1 attribute for now\n",
    "X_train_np = X_train.to_numpy().reshape(-1, 1)\n",
    "Y_train_np = Y_train.to_numpy().reshape(-1, 1)\n",
    "tree_clf.fit(X_train_np, Y_train_np)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (4,4), dpi=300)\n",
    "tree.plot_tree(tree_clf,\n",
    "               feature_names = features,\n",
    "               class_names = classes,\n",
    "               filled = True)\n",
    "\n",
    "fig.savefig('tree.png')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}